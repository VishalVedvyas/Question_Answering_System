{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/madhav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/madhav/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "package_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = os.path.join(package_dir,'Input.pdf')\n",
    "fp1 = open(input_file, 'rb')\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine\n",
    "extracted_text = ''\n",
    "parser = PDFParser(fp1)\n",
    "doc = PDFDocument()\n",
    "parser.set_document(doc)\n",
    "doc.set_parser(parser)\n",
    "doc.initialize('')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "laparams.char_margin = 1.0\n",
    "laparams.word_margin = 1.0\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "for page in doc.get_pages():\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    for lt_obj in layout:\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            extracted_text += lt_obj.get_text()\n",
    "text1 = extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "liabilities = ['cost', 'loss', 'expense', 'debt', 'liability', 'risk', 'loan', 'outflow', 'NOL', 'net operating loss', 'divest', 'net loss', 'borrowings', 'price', 'charge',\n",
    "'cost', 'expenditure', 'outlay', 'figure', 'impost', 'dues', 'tariff', 'valuation', 'appraisement', 'quotation', 'fare', 'hire', 'wages', \n",
    "'return', 'disbursement', 'rate', 'appraisal', 'reckoning', 'equivalent', 'payment', 'demand', 'barter', 'consideration', 'amount', 'credit', 'advance'\n",
    "'mortgage', 'overdraft', 'debenture', 'lending', 'advance']\n",
    "\n",
    "misc1 = ['market','share','quarter','fiscal','RMS','rate','average','estimate','tax','audit','interest','principle','budget','bill','finance','annual','business',\n",
    "'franchisee','cash','ROI','UDF','contribution','dividend','division','interest','percentage','proportion','stake','budgetary','economic','banking','commerce',\n",
    "'supply','demand','value','worth','deal']\n",
    "\n",
    "assets = [\n",
    "'revenue', 'profit', 'sale', 'credit', 'balance', 'asset', 'investment', 'amount', 'inflow', 'fund', 'sell', 'average final compensation', 'AFC', 'EBITDA', \n",
    "'acquisition', 'cost of goods sold', 'COGS', 'EVA', 'Economic value added', 'NP', 'net profit', 'operating income', 'income', 'return', 'yield', 'wealth', 'receipt', \n",
    "'stock', 'credit', 'dividend', 'perquisite', 'salary', 'annuity', 'acquirement', 'rent', 'gross revenue', 'appraisal', 'market price', 'grant', 'comepensation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sells VBZ FASS\n",
      "price NN FLIA\n",
      "average JJ FMIS\n",
      "profit NN FASS\n",
      "market NN FMIS\n",
      "share NN FMIS\n"
     ]
    }
   ],
   "source": [
    "f2 = open('Preprocess.txt','w')\n",
    "ne_tree = nltk.ne_chunk(pos_tag(word_tokenize(text1)))\n",
    "for tree_ob in ne_tree:\n",
    "    if(isinstance(tree_ob,tuple)):\n",
    "        word1 = wordnet_lemmatizer.lemmatize(tree_ob[0])\n",
    "        if word1 in liabilities:\n",
    "            print(tree_ob[0]+' '+tree_ob[1]+\" FLIA\",file = f2)\n",
    "            print(tree_ob[0]+' '+tree_ob[1]+\" FLIA\")\n",
    "        elif word1 in assets:\n",
    "            print(tree_ob[0]+' '+tree_ob[1]+\" FASS\",file = f2)\n",
    "            print(tree_ob[0]+' '+tree_ob[1]+\" FASS\")\n",
    "        elif word1 in misc1:\n",
    "            print(tree_ob[0]+' '+tree_ob[1]+\" FMIS\",file = f2)\n",
    "            print(tree_ob[0]+' '+tree_ob[1]+\" FMIS\")\n",
    "        else:\n",
    "            print(tree_ob[0]+' '+tree_ob[1]+\" O\",file = f2)\n",
    "    else:\n",
    "        for tree in tree_ob:\n",
    "            print(tree[0]+' '+tree[1]+' '+tree_ob.label(),file = f2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "test_data = open('Preprocess.txt','r')\n",
    "test_sents = list(test_data)\n",
    "\n",
    "\n",
    "def word2features(sent):\n",
    "    word = sent[0]\n",
    "    postag = sent[1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    sent1 = sent.split()\n",
    "    return [word2features(sent1)]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    sent1 = sent.split()\n",
    "    return [sent1[2]]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    sent1 = sent.split()\n",
    "    return [sent1[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "crf = joblib.load('NER.joblib')\n",
    "labels = list(crf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8739202999205768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madhav/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/madhav/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels))\n",
    "\n",
    "fin_ner_words = []\n",
    "for i in range(0,len(y_pred)):\n",
    "    tup = (X_test[i][0]['word.lower()'],str(y_pred[i][0]))\n",
    "    fin_ner_words.append(tup)\n",
    "    \n",
    "#print(fin_ner_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Apple is a multinational technology company that specializes in Computer services and products, which include consumer electronics, computer software, online services, software, and hardware. It designs, develops, and sells consumer electronics, computer software, and online services. The company's hardware products include the iPhone smartphone, the iPad tablet computer, the Mac personal computer, the iPod portable media player, the Apple Watch smartwatch, the digital media player, and the HomePod smart speaker. Apple's software includes the macOS and iOS operating systems, the iTunes media player, the Safari web browser, and the iLife and iWork creativity and productivity suites, as well as professional applications like Final Cut Pro, and Xcode. Its online services include the iTunes Store, the iOS App Store and Mac App Store, Apple Music, and iCloud. The company is a technological company. The company was founded by Steve Jobs. It was incorporated as Apple Computer, Inc. as the company name. The company went public and successes had followed them. Apple shipped new computers featuring innovative graphical user interfaces. The high price of its products caused problems. The company was founded on April 1, 1979. The average profit of the company is $ 800 billion. Apple lost market share to the lower-priced duopoly of Microsoft Windows on Intel PC clones. Gil Amelio was the second CEO of the company. Apple acquired NeXT. Jobs became the third CEO of the company. Apple swiftly returned to profitability.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "nermodel = os.path.join(package_dir,'stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.crf.ser.gz')\n",
    "nerjar = os.path.join(package_dir,'stanford-ner-2018-10-16/stanford-ner.jar')\n",
    "st = StanfordNERTagger(nermodel,nerjar,encoding='utf-8')\n",
    "\n",
    "text = extracted_text\n",
    "text1 = ''\n",
    "words = text.split()\n",
    "inPar = False\n",
    "for word in words:\n",
    "    if(word[0]=='('):\n",
    "        inPar = True\n",
    "    if(inPar == False):\n",
    "        text1 = text1+ ' ' + word\n",
    "    if(word[len(word)-1]==')'):\n",
    "        inPar = False    \n",
    "    if(word[len(word)-2]==')'):\n",
    "        inPar = False\n",
    "        text1 = text1 + word[len(word)-1]\n",
    "text = text1.replace('\"','\\'')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_text = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Apple', 'PERSON')\n",
      "('is', 'O')\n",
      "('a', 'O')\n",
      "('multinational', 'O')\n",
      "('technology', 'O')\n",
      "('company', 'O')\n",
      "('that', 'O')\n",
      "('specializes', 'O')\n",
      "('in', 'O')\n",
      "('Computer', 'PERSON')\n",
      "('services', 'O')\n",
      "('and', 'O')\n",
      "('products', 'O')\n",
      "(',', 'O')\n",
      "('which', 'O')\n",
      "('include', 'O')\n",
      "('consumer', 'O')\n",
      "('electronics', 'O')\n",
      "(',', 'O')\n",
      "('computer', 'O')\n",
      "('software', 'O')\n",
      "(',', 'O')\n",
      "('online', 'O')\n",
      "('services', 'O')\n",
      "(',', 'O')\n",
      "('software', 'O')\n",
      "(',', 'O')\n",
      "('and', 'O')\n",
      "('hardware', 'O')\n",
      "('.', 'O')\n",
      "('It', 'O')\n",
      "('designs', 'O')\n",
      "(',', 'O')\n",
      "('develops', 'O')\n",
      "(',', 'O')\n",
      "('and', 'O')\n",
      "('sells', 'FASS')\n",
      "('consumer', 'O')\n",
      "('electronics', 'O')\n",
      "(',', 'O')\n",
      "('computer', 'O')\n",
      "('software', 'O')\n",
      "(',', 'O')\n",
      "('and', 'O')\n",
      "('online', 'O')\n",
      "('services', 'O')\n",
      "('.', 'O')\n",
      "('The', 'O')\n",
      "('company', 'O')\n",
      "(\"'s\", 'O')\n",
      "('hardware', 'O')\n",
      "('products', 'O')\n",
      "('include', 'O')\n",
      "('the', 'O')\n",
      "('iPhone', 'O')\n",
      "('smartphone', 'O')\n",
      "(',', 'O')\n",
      "('the', 'O')\n",
      "('iPad', 'O')\n",
      "('tablet', 'O')\n",
      "('computer', 'O')\n",
      "(',', 'O')\n",
      "('the', 'O')\n",
      "('Mac', 'PERSON')\n",
      "('personal', 'O')\n",
      "('computer', 'O')\n",
      "(',', 'O')\n",
      "('the', 'O')\n",
      "('iPod', 'O')\n",
      "('portable', 'O')\n",
      "('media', 'O')\n",
      "('player', 'O')\n",
      "(',', 'O')\n",
      "('the', 'O')\n",
      "('Apple', 'PERSON')\n",
      "('Watch', 'PERSON')\n",
      "('smartwatch', 'O')\n",
      "(',', 'O')\n",
      "('the', 'O')\n",
      "('digital', 'O')\n",
      "('media', 'O')\n",
      "('player', 'O')\n",
      "(',', 'O')\n",
      "('and', 'O')\n",
      "('the', 'O')\n",
      "('HomePod', 'O')\n",
      "('smart', 'O')\n",
      "('speaker', 'O')\n",
      "('.', 'O')\n",
      "('Apple', 'PERSON')\n",
      "(\"'s\", 'O')\n",
      "('software', 'O')\n",
      "('includes', 'O')\n",
      "('the', 'O')\n",
      "('macOS', 'O')\n",
      "('and', 'O')\n",
      "('iOS', 'O')\n",
      "('operating', 'O')\n",
      "('systems', 'O')\n",
      "(',', 'O')\n",
      "('the', 'O')\n",
      "('iTunes', 'O')\n",
      "('media', 'O')\n",
      "('player', 'O')\n",
      "(',', 'O')\n",
      "('the', 'O')\n",
      "('Safari', 'ORGANIZATION')\n",
      "('web', 'O')\n",
      "('browser', 'O')\n",
      "(',', 'O')\n",
      "('and', 'O')\n",
      "('the', 'O')\n",
      "('iLife', 'O')\n",
      "('and', 'O')\n",
      "('iWork', 'O')\n",
      "('creativity', 'O')\n",
      "('and', 'O')\n",
      "('productivity', 'O')\n",
      "('suites', 'O')\n",
      "(',', 'O')\n",
      "('as', 'O')\n",
      "('well', 'O')\n",
      "('as', 'O')\n",
      "('professional', 'O')\n",
      "('applications', 'O')\n",
      "('like', 'O')\n",
      "('Final', 'ORGANIZATION')\n",
      "('Cut', 'PERSON')\n",
      "('Pro', 'PERSON')\n",
      "(',', 'O')\n",
      "('and', 'O')\n",
      "('Xcode', 'PERSON')\n",
      "('.', 'O')\n",
      "('Its', 'O')\n",
      "('online', 'O')\n",
      "('services', 'O')\n",
      "('include', 'O')\n",
      "('the', 'O')\n",
      "('iTunes', 'O')\n",
      "('Store', 'ORGANIZATION')\n",
      "(',', 'O')\n",
      "('the', 'O')\n",
      "('iOS', 'O')\n",
      "('App', 'ORGANIZATION')\n",
      "('Store', 'ORGANIZATION')\n",
      "('and', 'O')\n",
      "('Mac', 'ORGANIZATION')\n",
      "('App', 'ORGANIZATION')\n",
      "('Store', 'ORGANIZATION')\n",
      "(',', 'O')\n",
      "('Apple', 'ORGANIZATION')\n",
      "('Music', 'ORGANIZATION')\n",
      "(',', 'O')\n",
      "('and', 'O')\n",
      "('iCloud', 'O')\n",
      "('.', 'O')\n",
      "('The', 'O')\n",
      "('company', 'O')\n",
      "('is', 'O')\n",
      "('a', 'O')\n",
      "('technological', 'O')\n",
      "('company', 'O')\n",
      "('.', 'O')\n",
      "('The', 'O')\n",
      "('company', 'O')\n",
      "('was', 'O')\n",
      "('founded', 'O')\n",
      "('by', 'O')\n",
      "('Steve', 'PERSON')\n",
      "('Jobs', 'PERSON')\n",
      "('.', 'O')\n",
      "('It', 'O')\n",
      "('was', 'O')\n",
      "('incorporated', 'O')\n",
      "('as', 'O')\n",
      "('Apple', 'ORGANIZATION')\n",
      "('Computer', 'ORGANIZATION')\n",
      "(',', 'ORGANIZATION')\n",
      "('Inc.', 'ORGANIZATION')\n",
      "('as', 'O')\n",
      "('the', 'O')\n",
      "('company', 'O')\n",
      "('name', 'O')\n",
      "('.', 'O')\n",
      "('The', 'O')\n",
      "('company', 'O')\n",
      "('went', 'O')\n",
      "('public', 'O')\n",
      "('and', 'O')\n",
      "('successes', 'O')\n",
      "('had', 'O')\n",
      "('followed', 'O')\n",
      "('them', 'O')\n",
      "('.', 'O')\n",
      "('Apple', 'PERSON')\n",
      "('shipped', 'O')\n",
      "('new', 'O')\n",
      "('computers', 'O')\n",
      "('featuring', 'O')\n",
      "('innovative', 'O')\n",
      "('graphical', 'O')\n",
      "('user', 'O')\n",
      "('interfaces', 'O')\n",
      "('.', 'O')\n",
      "('The', 'O')\n",
      "('high', 'O')\n",
      "('price', 'FLIA')\n",
      "('of', 'O')\n",
      "('its', 'O')\n",
      "('products', 'O')\n",
      "('caused', 'O')\n",
      "('problems', 'O')\n",
      "('.', 'O')\n",
      "('The', 'O')\n",
      "('company', 'O')\n",
      "('was', 'O')\n",
      "('founded', 'O')\n",
      "('on', 'O')\n",
      "('April', 'DATE')\n",
      "('1', 'DATE')\n",
      "(',', 'DATE')\n",
      "('1979', 'DATE')\n",
      "('.', 'O')\n",
      "('The', 'O')\n",
      "('average', 'FMIS')\n",
      "('profit', 'FASS')\n",
      "('of', 'O')\n",
      "('the', 'O')\n",
      "('company', 'O')\n",
      "('is', 'O')\n",
      "('$', 'MONEY')\n",
      "('800', 'MONEY')\n",
      "('billion', 'MONEY')\n",
      "('.', 'O')\n",
      "('Apple', 'O')\n",
      "('lost', 'O')\n",
      "('market', 'FMIS')\n",
      "('share', 'FMIS')\n",
      "('to', 'O')\n",
      "('the', 'O')\n",
      "('lower-priced', 'O')\n",
      "('duopoly', 'O')\n",
      "('of', 'O')\n",
      "('Microsoft', 'ORGANIZATION')\n",
      "('Windows', 'ORGANIZATION')\n",
      "('on', 'O')\n",
      "('Intel', 'ORGANIZATION')\n",
      "('PC', 'ORGANIZATION')\n",
      "('clones', 'O')\n",
      "('.', 'O')\n",
      "('Gil', 'PERSON')\n",
      "('Amelio', 'PERSON')\n",
      "('was', 'O')\n",
      "('the', 'O')\n",
      "('second', 'O')\n",
      "('CEO', 'ORGANIZATION')\n",
      "('of', 'O')\n",
      "('the', 'O')\n",
      "('company', 'O')\n",
      "('.', 'O')\n",
      "('Apple', 'PERSON')\n",
      "('acquired', 'O')\n",
      "('NeXT', 'O')\n",
      "('.', 'O')\n",
      "('Jobs', 'PERSON')\n",
      "('became', 'O')\n",
      "('the', 'O')\n",
      "('third', 'O')\n",
      "('CEO', 'ORGANIZATION')\n",
      "('of', 'O')\n",
      "('the', 'O')\n",
      "('company', 'O')\n",
      "('.', 'O')\n",
      "('Apple', 'PERSON')\n",
      "('swiftly', 'O')\n",
      "('returned', 'O')\n",
      "('to', 'O')\n",
      "('profitability', 'O')\n",
      "('.', 'O')\n"
     ]
    }
   ],
   "source": [
    "classified_text = st.tag(tokenized_text)\n",
    "tagged_words = []\n",
    "\n",
    "fin_ner_text = [(l1,s1,s2) for (l1,s1),(l2,s2) in zip(classified_text,fin_ner_words)]\n",
    "F_mon = ['rupees', 'rupee', 'rs', 'dollar', '$']\n",
    "Org = []\n",
    "Loc = []\n",
    "Per = []\n",
    "#print(fin_ner_text)\n",
    "for word in fin_ner_text:\n",
    "    lst = list(word)\n",
    "    if(lst[1] == 'ORGANIZATION'):\n",
    "        Org.append(lst[0].lower())\n",
    "    elif(lst[1] == 'LOCATION'):\n",
    "        Loc.append(lst[0].lower())\n",
    "    elif(lst[1] == 'PERSON'):\n",
    "        Per.append(lst[0].lower())\n",
    "    elif(lst[1] == 'O' and wordnet_lemmatizer.lemmatize(lst[0]).lower() in F_mon):\n",
    "        lst[1] = 'FMON'\n",
    "    elif(lst[1] == 'O'):\n",
    "        lst[1] = lst[2]\n",
    "    word = tuple(lst)\n",
    "    tagged_words.append(word)\n",
    "        \n",
    "for word in tagged_words:\n",
    "    print((word[0],word[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quesgen = os.path.join(package_dir,'question_generation-master')\n",
    "os.chdir(quesgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/model.t7: OK\n",
      "----------------Installing python requirements----------------\n",
      "Requirement already satisfied: pycorenlp==0.3.0 in /home/madhav/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: pyzmq==16.0.2 in /home/madhav/anaconda3/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (16.0.2)\n",
      "Requirement already satisfied: requests in /home/madhav/anaconda3/lib/python3.6/site-packages (from pycorenlp==0.3.0->-r requirements.txt (line 1)) (2.7.0)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "----------------Pulling corenlp and opennmt docker images----------------\n",
      "----------------Running corenlp and opennmt servers----------------\n",
      "[sudo] password for madhav: a3d613a98065b45b0b641b31d821e5640d6fd378bad517bbfbf2d7735c953e73\n",
      "3c5cd96e58459686b581460072cb5fe493e5c86ee5ee6e6c533c244efddc1631\n",
      "----------------Test output----------------\n",
      " Apple is a multinational technology company that specializes in Computer services and products, which include consumer electronics, computer software, online services, software, and hardware. It designs, develops, and sells consumer electronics, computer software, and online services. The company's hardware products include the iPhone smartphone, the iPad tablet computer, the Mac personal computer, the iPod portable media player, the Apple Watch smartwatch, the digital media player, and the HomePod smart speaker. Apple's software includes the macOS and iOS operating systems, the iTunes media player, the Safari web browser, and the iLife and iWork creativity and productivity suites, as well as professional applications like Final Cut Pro, and Xcode. Its online services include the iTunes Store, the iOS App Store and Mac App Store, Apple Music, and iCloud. The company is a technological company. The company was founded by Steve Jobs. It was incorporated as Apple Computer, Inc. as the company name. The company went public and successes had followed them. Apple shipped new computers featuring innovative graphical user interfaces. The high price of its products caused problems. The company was founded on April 1, 1979. The average profit of the company is $ 800 billion. Apple lost market share to the lower-priced duopoly of Microsoft Windows on Intel PC clones. Gil Amelio was the second CEO of the company. Apple acquired NeXT. Jobs became the third CEO of the company. Apple swiftly returned to profitability.\n",
      "when was the company founded ?\tapril 1 , 1979\t-0.95197695493698\n",
      "who was the second ceo of the company ?\tgil amelio\t-1.587094783783\n",
      "who founded the company ?\tsteve jobs\t-3.1549923419952\n",
      "what was the third ceo of the company ?\tthird\t-4.7447009086609\n",
      "what is the name of the company ?\tapple computer , inc.\t-4.7784662246704\n",
      "what is the average profit of the company ?\t$ 800 billion\t-4.9303951263428\n",
      "what was the original ceo of the company ?\tsecond\t-5.1591777801514\n",
      "what computer was the ipod 's personal computer player ?\tmac\t-6.3388957977295\n",
      "what microsoft was the market share of windows on intel ?\tmicrosoft\t-7.0734705924988\n",
      "who was the market share of microsoft ?\tapple\t-7.1252355575562\n",
      "who is a populist technology company ?\tapple\t-7.7810769081116\n",
      "what apple 's software includes what software touch ?\tapple\t-10.731921195984\n",
      "what company did apple lose to the imac 8 of microsoft ?\tintel\t-10.980400085449\n",
      "----------------Stopping containers----------------\n",
      "corenlp\n",
      "corenlp\n",
      "opennmt\n",
      "opennmt\n"
     ]
    }
   ],
   "source": [
    "!./setup \"$text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "posmodel = os.path.join(package_dir,'stanford-postagger-full-2018-10-16/models/english-bidirectional-distsim.tagger')\n",
    "posjar = os.path.join(package_dir,'stanford-postagger-full-2018-10-16/stanford-postagger.jar')\n",
    "posTagger = StanfordPOSTagger(posmodel,posjar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what is the average profit of the company ?\\t$ 800 billion\\t-4.9303951263428', -0.9303951263428001, 'MONEY'), ('when was the company founded ?\\tapril 1 , 1979\\t-0.95197695493698', -0.95197695493698, 'DATE'), ('who was the second ceo of the company ?\\tgil amelio\\t-1.587094783783', -1.587094783783, 'PERSON'), ('who founded the company ?\\tsteve jobs\\t-3.1549923419952', -3.1549923419952, 'PERSON'), ('what was the third ceo of the company ?\\tthird\\t-4.7447009086609', -4.7447009086609, 'O'), ('what is the name of the company ?\\tapple computer , inc.\\t-4.7784662246704', -4.7784662246704, 'ORGANIZATION')]\n"
     ]
    }
   ],
   "source": [
    "questions_path = os.path.join(package_dir,'question_generation-master/questions.txt')\n",
    "lines = [line.rstrip('\\n') for line in open(questions_path)]\n",
    "rank_list = []\n",
    "\n",
    "unique_list1 = []\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    tokenized_text = word_tokenize(line)\n",
    "    capitalized_text = []\n",
    "    for word in tokenized_text:\n",
    "        word = word.capitalize()\n",
    "        capitalized_text.append(word)\n",
    "    \n",
    "    classified_text = st.tag(tokenized_text)\n",
    "    pos_text = posTagger.tag(tokenized_text)\n",
    "    pos_ner_text = [(l1,s1,s2) for (l1,s1),(l2,s2) in zip(classified_text,pos_text)]\n",
    "    \n",
    "    tagged_questions = []\n",
    "    count = 0\n",
    "    que_end = 0\n",
    "    ans = 0\n",
    "    \n",
    "    if(line.split('?')[0] not in unique_list1):\n",
    "        unique_list1.append(line.split('?')[0])\n",
    "    else:\n",
    "        count = count+1\n",
    "    \n",
    "    for word in pos_ner_text:\n",
    "        lst = list(word)\n",
    "        lst_ner = list(word)\n",
    "        if(lst[0] in Org):\n",
    "            lst[1] = 'ORGANIZATION'\n",
    "        elif(lst[0] in Loc):\n",
    "            lst[1] = 'LOCATION'\n",
    "        elif(lst[0] in Per):\n",
    "            lst[1] = 'PERSON'\n",
    "        if(lst[0] == '?'):\n",
    "            que_end = 1\n",
    "        elif(que_end != 1):\n",
    "            if(lst[1] != 'O' or lst[2] == 'NNP'):\n",
    "                count = count - 1\n",
    "                #print(lst[0])\n",
    "                if(lst[1] == 'ORGANIZATION'):\n",
    "                    lst[0] = 'the company'\n",
    "            if(lst[1] == 'O' and wordnet_lemmatizer.lemmatize(lst[0]).lower() in assets):\n",
    "                lst[1] = 'FASS'\n",
    "                count = count+2\n",
    "            elif(lst[1] == 'O' and wordnet_lemmatizer.lemmatize(lst[0]).lower() in liabilities):\n",
    "                lst[1] = 'FLIA'\n",
    "                count = count+2\n",
    "            elif(lst[1] == 'O' and wordnet_lemmatizer.lemmatize(lst[0]).lower() in misc1):\n",
    "                lst[1] = 'FMIS'\n",
    "                count = count+2\n",
    "            elif(lst[1] == 'O' and wordnet_lemmatizer.lemmatize(lst[0]).lower() in F_mon):\n",
    "                lst[1] = 'FMON'\n",
    "                count = count+2\n",
    "        elif(ans != 1):\n",
    "            tag = lst[1]\n",
    "            ans = 1\n",
    "        word = tuple(lst)\n",
    "        word_ner = tuple(lst_ner)\n",
    "        tagged_questions.append(word)\n",
    "    \n",
    "    if(float(tokenized_text[len(classified_text)-1]) >= -5):\n",
    "        tup = (line, float(tokenized_text[len(classified_text)-1]) + count, tag)\n",
    "        rank_list.append(tup)\n",
    "    rank_list = sorted(rank_list,key=lambda x: x[1],reverse = True)\n",
    "print(rank_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what is the average profit of the company ?', 'when was the company founded ?', 'who was the second ceo of the company ?', 'who founded the company ?', 'what was the third ceo of the company ?', 'what is the name of the company ?']\n"
     ]
    }
   ],
   "source": [
    "unique_list = []\n",
    "questions_path = os.path.join(package_dir,'question_generation-master/questions_ranked.txt')\n",
    "sample = open(questions_path,'r+')\n",
    "for line in rank_list:\n",
    "    if(line[0].split('\\t')[0] not in unique_list):\n",
    "        unique_list.append(line[0].split('\\t')[0])\n",
    "        print(\"{} ~~ {}\".format(line[0].split('\\t')[0], line[2].split('\\t')[0]),file = sample)\n",
    "print(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power Finance Corporation (PFC) completed \n",
      "acquisition of majority stake in REC Ltd on 24th July. They transferred Rs 14,500 crore to the government. \n",
      "PFC is hopeful of merger of the two firms in 2019-20.  \n",
      "PFC has financed 70 per cent of the deal from cash inflows and the balance 30 per cent is through debt. \n",
      "PFC borrowed around Rs 88,000 crore. 50 per cent of Rs 88,000 has been through term \n",
      "loans. The loans availed from banks are mostly based on marginal cost of funds-based lending rate (MCLR). \n",
      "PFC's loan assets would be around Rs 6 lakh crore. On the basis of 2017-18 financials, the \n",
      "consolidated annual income would be about Rs 50,000 crore and annual profit about Rs 11,000 crore. \n",
      "PFC would have higher strategic importance in financing \n",
      "of the power sector. PFC, therefore, will be a dominant player not only in the power sector but also in the entire \n",
      "financial market space. \n",
      "PFC will be the second-largest government-owned financial player in the country. Largest financial player is \n",
      "State Bank of \n",
      "India (SBI). PFC will be third-highest profit making financial player in India. Highest profit making financial \n",
      "player in India are HDFC respectively. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(package_dir,'Test.pdf')\n",
    "fp1 = open(test_path, 'rb')\n",
    "parser = PDFParser(fp1)\n",
    "doc = PDFDocument()\n",
    "parser.set_document(doc)\n",
    "doc.set_parser(parser)\n",
    "doc.initialize('')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "laparams.char_margin = 1.0\n",
    "laparams.word_margin = 1.0\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "extracted_text1 = ''\n",
    "\n",
    "for page in doc.get_pages():\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    for lt_obj in layout:\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            extracted_text1 += lt_obj.get_text()\n",
    "print(extracted_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ansext = os.path.join(package_dir,'DeepPavlov')\n",
    "os.chdir(ansext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/madhav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/madhav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/madhav/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/madhav/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2019-05-09 22:48:02.241 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/madhav/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "INFO:deeppavlov.models.preprocessors.squad_preprocessor:SquadVocabEmbedder: loading saved tokens vocab from /home/madhav/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2019-05-09 22:48:02.452 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/madhav/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "INFO:deeppavlov.models.preprocessors.squad_preprocessor:SquadVocabEmbedder: loading saved chars vocab from /home/madhav/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "/home/madhav/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "2019-05-09 22:48:06.941 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "INFO:deeppavlov.core.layers.tf_layers:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "WARNING:tensorflow:From /home/madhav/Desktop/Project/DeepPavlov/deeppavlov/core/layers/tf_layers.py:808: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /home/madhav/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "2019-05-09 22:48:14.802 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "INFO:deeppavlov.core.layers.tf_layers:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2019-05-09 22:48:14.922 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "INFO:deeppavlov.core.layers.tf_layers:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2019-05-09 22:48:15.11 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "INFO:deeppavlov.core.layers.tf_layers:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "WARNING:tensorflow:From /home/madhav/Desktop/Project/DeepPavlov/deeppavlov/models/squad/squad.py:211: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "2019-05-09 22:48:25.131 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 50: [loading model from /home/madhav/.deeppavlov/models/squad_model/model]\n",
      "INFO:deeppavlov.core.models.tf_model:[loading model from /home/madhav/.deeppavlov/models/squad_model/model]\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model, configs\n",
    "\n",
    "model = build_model(configs.squad.squad, download=False)\n",
    "\n",
    "#context_file_name = input(\"Enter context file name: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what is the average profit of the company ? ~~ MONEY', 'when was the company founded ? ~~ DATE', 'who was the second ceo of the company ? ~~ PERSON', 'who founded the company ? ~~ PERSON', 'what was the third ceo of the company ? ~~ O', 'what is the name of the company ? ~~ ORGANIZATION', '', 'what was the net revenue of the company ? ~~ MONEY', 'what was the third ceo of the company ? ~~ O', 'what is the name of the company ? ~~ ORGANIZATION', \"d's largest software maker?\", 'for how much did microsoft acquire linkedin?', 'how much did skype cost microsoft?']\n",
      "['Rs 11,000 crore'] O  MONEY Answer Type Not Matched\n",
      "['24th July'] O  DATE Answer Type Not Matched\n",
      "['Power Finance Corporation'] ORGANIZATION  PERSON Answer Type Not Matched\n",
      "['Power Finance Corporation'] ORGANIZATION  PERSON Answer Type Not Matched\n",
      "['HDFC'] O  O Matched Answer Type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-09 22:49:49.120 INFO in 'deeppavlov.models.squad.squad'['squad'] at line 297: SQuAD model: Warning! Empty question or context was found.\n",
      "INFO:deeppavlov.models.squad.squad:SQuAD model: Warning! Empty question or context was found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Power Finance Corporation'] ORGANIZATION  ORGANIZATION Matched Answer Type\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f4db524e28e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mF_mon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mner_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F_MON\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mexp_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mner_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexp_ner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mner_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp_ner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Matched Answer Type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "context = extracted_text1\n",
    "questions_path = os.path.join(package_dir,'question_generation-master/questions_ranked.txt')\n",
    "sample = open(questions_path,'r+')\n",
    "#questions_file_name = input(\"Enter questions file name: \")\n",
    "questions = sample.read()\n",
    "questions_list = (questions.split(\"\\n\"))[0:-1]\n",
    "print(questions_list)\n",
    "for question in questions_list:\n",
    "    x = question.split(\"~~\")\n",
    "    y = model([context], [x[0]])\n",
    "    ans = y[0]\n",
    "    ner_ans = st.tag(word_tokenize(ans[0]))\n",
    "    if(ans in assets):\n",
    "        ner_ans = \"F_ASS\"\n",
    "    elif(ans in liabilities):\n",
    "        ner_ans = \"F_LIA\"\n",
    "    elif(ans in misc1):\n",
    "        ner_ans = \"F_MIS\"\n",
    "    elif(ans in F_mon):\n",
    "        ner_ans = \"F_MON\"\n",
    "    exp_ner = x[1]\n",
    "    if(\" \"+ner_ans[0][1] == exp_ner):\n",
    "        print(ans, ner_ans[0][1],exp_ner, 'Matched Answer Type')\n",
    "    else:\n",
    "        print(ans, ner_ans[0][1],exp_ner, 'Answer Type Not Matched')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
